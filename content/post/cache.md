---
# Basic info
title: "Cache"
date: 2020-07-27
draft: false
# type: docs # page type
authors: ["admin"]
tags: ["Computer Structure", "Cache"]
categories: ["Computer Structure"]
toc: true # Show table of contents?

# Advanced settings
profile: false  # Show author profile?

reading_time: true # Show estimated reading time?
summary: "How does cache work in computer structure?"
share: false  # Show social sharing links?
featured: true
lastmod: true

comments: false  # Show comments?
disable_comment: true
commentable: false  # Allow visitors to comment? Supported by the Page, Post, and Docs content types.

editable: false  # Allow visitors to edit the page? Supported by the Page, Post, and Docs content types.

# Optional header image (relative to `static/img/` folder).
header:
  image: ""
  caption: ""
  
---





Immer groÌˆÃŸer werdende LuÌˆcke zwischen Verarbeitungsgeschwindigkeit von Prozessoren und Zugriffsgeschwindigkeit der DRAM-Speicherchips des Hauptspeichers

Ein technologisch einheitlicher Speicher mit kurzer Zugriffszeit und groÃŸer KapazitaÌˆt ist aus KostengruÌˆnden i. A. nicht realisierbarã€‚

**ğŸ”§ LoÌˆsung: Hierarchische Anordnung verschiedener Speicher und Verschiebung der Information zwischen den Schichten (Speicherhierarchie)**

## Speicherhierarchie


zum **Ausgleich** der unterschiedlichen Zugriffszeiten der CPU und des Hauptspeichers.

2 Strategien:

+ **Cache-Speicher**:

  **Kurze Zugriffszeiten** ------> Beschleunigung des Prozessorzugriffs.

+ **Virtueller Speicher**:

  **VergrÃ¶ÃŸerung** des tatsÃ¤chlich vorhandenen Hauptspeichers (z. B. bei gleichzeitiger Bearbeitung mehrerer Prozesse)

| Speicherhierarchie                                     |      |
| ------------------------------------------------------ | ---- |
| Register                                               |      |
| on-chip Cache                                          |      |
| secondary level Cache (SRAM)                           |      |
| Arbeitsspeicher (DRAM)                                 |      |
| SekundÃ¤rspeicher(Platten, elektronishe Massenspeicher) |      |
| Archivspeicher(Platten, BÃ¤nder, optische Platten)      |      |

von Unten nach Oben:

+ Zunehmende Kosten/Byte 

+ Abnehmende KapazitaÌˆt

+ Abnehmende Zugriffszeit

## Cache Speicher

### Problem : 

+ die Buszykluszeit moderner Prozessoren ist **kuerzer** als die Zykluszeit preiswerter, groÃŸer DRAM-Bausteine

  --------> dies zwingt zum **EinfuÌˆgen von Wartezyklen**

+ SRAM-Bausteine hingegen, die ohne Wartezyklen betrieben
  werden koÌˆnnen, sind jedoch klein und teuer. (*å­˜å–å‘¨æœŸtRCä¸ç­‰äºè®¿é—®æ—¶é—´tAAæ˜¯SRAMå’ŒDRAMçš„ä¸»è¦åŒºåˆ«ä¹‹ä¸€ã€‚*)

    --------> nur **kleine** Speicher koÌˆnnen so aufgebaut werden

### LoÌˆsung des Problems:

**zwischen** den **Prozessor** und den relativ langsamen, aber billigen **Hauptspeicher** aus DRAM-Bausteinen legt man einen **kleinen, schnellen Speicher** aus **SRAM- Bausteinen**, den sogenannten **Cache-Speicher.**

**Prozessor <---> Cache Speicher(besteht aus SRAM)<--> Hauptspeicher** 

**Auf den Cache-Speicher soll der Prozessor fast so schnell wie auf seine Register zugreifen koÌˆnnen.**

### 2 Arten (siehe Folien14 s10)

#### 1. On-Chip-Cache: integriert auf dem Prozessorchip

+ **Sehr kurze Zugriffszeiten** (wie die der
  prozessorinternen Register)

+ Aus technologischen GruÌˆnden **begrenzte KapazitaÌˆt**


#### 2. Off-Chip-Cache: prozessorextern


### Nutzen

1. **Verbesserung der Zugriffszeit des Hauptspeichers eines Prozessors** durch einen Cache **zur Vermeidung von Wartezyklen** (CPU-Cache, Befehls- und Daten-Cache).

2. Verbesserung der Zugriffszeit von Plattenspeichern durch einen Cache (**Plattencache**)

### CPU-Cache-Speicher

#### Definition

ein **kleiner**, **schneller** **Pufferspeicher**, in dem **Kopien derjenigen Teile des Hauptsspeichers bereitgehalten werden**, auf die mit hoher Wahrscheinlichkeit von der CPU als naÌˆchstes zugegriffen wird.

#### Wieso kommt es zur einer Leistungssteigerung?

Ein CPU-Cache-Speicher bezieht seine Effizienz im wesentlichen **aus der LokalitaÌˆtseigenschaft von Programmen (locality of reference)**, 

d.h. es werden bestimmte Speicherzellen bevorzugt und wiederholt angesprochen (z.B. Programmschleifen)

> ç¨‹åºçš„å±€éƒ¨æ€§åŸç†ï¼ˆlocality of  referenceï¼‰ï¼šCPUå½“å‰æ‰€éœ€è¦ä½¿ç”¨çš„æŒ‡ä»¤æˆ–æ•°æ®åœ¨å­˜å‚¨å™¨ä¸­å¾ˆå¯èƒ½æ˜¯åœ¨åŒä¸€åœ°å€çš„é™„è¿‘ã€‚

+ **Zeitliche LokalitaÌˆt**

  Die Information, die **in naher Zukunft angesprochen** wird, ist mit groÃŸer Wahrscheinlichkeit **schon fruÌˆher einmal angesprochen worden** (Schleifen)

+ **OÌˆrtliche LokalitaÌˆt**

  Ein zukuÌˆnftiger Zugriff wird mit groÃŸer Wahrscheinlichkeit **in der NaÌˆhe** des bisherigen Zugriffs liegen (Tabellen, Arrays).


#### Funktionsweise

> Cacheå·¥ä½œåŸç†ï¼š
>
> å½“CPUéœ€è¦æ•°æ®æˆ–æŒ‡ä»¤æ—¶, å®ƒé¦–å…ˆè®¿é—®Cacheï¼Œçœ‹çœ‹æ‰€éœ€è¦çš„æ•°æ®æˆ–æŒ‡ä»¤æ˜¯å¦å­˜åœ¨äºCacheä¸­ï¼Œæ–¹æ³•æ˜¯ï¼š
>
> å°†CPUæä¾›çš„æ•°æ®æˆ–æŒ‡ä»¤åœ¨å†…å­˜ä¸­å­˜æ”¾ä½ç½®çš„å†…å­˜åœ°å€ ä¸ Cacheä¸­å·²å­˜æ”¾çš„æ•°æ®æˆ–æŒ‡ä»¤çš„åœ°å€ç›¸æ¯”ä»·ã€‚
>
> - ç›¸ç­‰ 
>
>   --> è¯´æ˜å¯ä»¥åœ¨Cacheä¸­æ‰¾åˆ°æ‰€éœ€çš„æ•°æ®æˆ–æŒ‡ä»¤ï¼ˆcacheå‘½ä¸­ï¼‰--> ä¸éœ€è¦ä»»ä½•ç­‰å¾…çŠ¶æ€ï¼Œ Cacheç›´æ¥æŠŠä¿¡æ¯ä¼ ç»™CPU
>
> - ä¸ç›¸ç­‰ 
>
>   --> CPUæ‰€éœ€çš„æ•°æ®æˆ–æŒ‡ä»¤ä¸åœ¨Cacheä¸­ï¼ˆæœªå‘½ä¸­ï¼‰ï¼Œéœ€è¦åˆ°å†…å­˜ä¸­æå–:
>
> å­˜å‚¨å™¨æ§åˆ¶ç”µè·¯ä»å†…å­˜ä¸­å–å‡ºæ•°æ®æˆ–æŒ‡ä»¤ä¼ é€ç»™CPUï¼Œ**åŒæ—¶åœ¨Cacheä¸­æ‹·è´ä¸€ä»½å‰¯æœ¬**ã€‚ï¼ˆä¸ºäº†é˜²æ­¢CPUä»¥ååœ¨è®¿é—®åŒä¸€ä¿¡æ¯æ—¶åˆä¼šå‡ºç°ä¸å‘½ä¸­çš„æƒ…å†µï¼Œä»è€Œé™ä½CPUè®¿é—®é€Ÿåº¦ç›¸å¯¹è¾ƒæ…¢çš„å†…å­˜çš„æ¦‚ç‡ï¼‰ã€‚
>
>
> æ¢è€Œè¨€ä¹‹ï¼ŒCacheå‘½ä¸­ç‡è¶Šé«˜ï¼Œç³»ç»Ÿæ€§èƒ½è¶Šå¥½ --> è¿™è¦æ±‚ä»»ä½•æ—¶åˆ»cacheæ§åˆ¶å™¨éƒ½è¦çŸ¥é“cacheä¸­å­˜å‚¨çš„æ˜¯ä»€ä¹ˆæŒ‡ä»¤ã€æ•°æ®ã€‚  
>
> Cacheçš„å‘½ä¸­ç‡å–å†³äºä¸‹é¢ä¸‰ä¸ªå› ç´ ï¼š
>
>   + Cacheçš„å¤§å°
>
>     å®¹é‡ç›¸å¯¹è¾ƒå¤§çš„Cacheï¼Œå‘½ä¸­ç‡ä¼šç›¸åº”çš„æé«˜
>
>   + Cacheçš„ç»„ç»‡ç»“æ„
>
>   + ç¨‹åºçš„ç‰¹æ€§
>
>     éµå¾ªå±€éƒ¨æ€§åŸç†ï¼ˆlocality of referenceï¼Œ LokalitaÌˆtseigenschaft von Programmenï¼‰çš„ç¨‹åºåœ¨è¿è¡Œæ—¶ï¼ŒCacheå‘½ä¸­ç‡ä¹Ÿä¼šå¾ˆé«˜ã€‚

#### Lseszugriff(siehe Folien14 s16)

Vor jedem Lesezugriff pruÌˆft der Î¼P, ob das Datum im Cache steht.

+ Wenn ja: **Treffer (read hit)**

  das Datum kann **ohne Wartezyklen** aus dem Cache entnommen werden. 

+ Wenn nein: **kein Treffer (read miss)**

  das Datum wird **mit Wartezyklen aus dem Arbeitsspeicher gelesen** und **gleichzeitig in den Cache eingefuÌˆgt.** 

#### Schreibzugriffe

+ Liegt beim Schreiben ein **Cache-Miss (write miss)** vor, wird **das Datum sowohl in den Arbeitsspeicher als auch in den Cache geschrieben**.

+ Liegt beim Schreiben jedoch ein **Cache-Hit (write hit)** vor, d.h. **ein im Cache stehendes Datum wird durch den Prozessor veraÌˆndert**    

**---> verschiedene Organisationsformen:**

1. **Durchschreibverfahren: (write through policy)**

   Ein Datum wird von der CPU **immer gleichzeitig** in den **Cache-** und in den **Arbeitsspeicher** geschrieben.

   + Vorteil: **garantierte Konsistenz** zwischen Cache- und Arbeitsspeicher.

   + Nachteil: Schreibzugriffe **benoÌˆtigen immer die langsame Zykluszeit** des Hauptspeichers und belasten den Systembus.

   > 1ï¼ç›´å†™å¼ï¼ˆwrite throughï¼‰
   >
   > å³CPUåœ¨å‘Cacheå†™å…¥æ•°æ®çš„åŒæ—¶ï¼Œä¹ŸæŠŠæ•°æ®å†™å…¥ä¸»å­˜ä»¥ä¿è¯Cacheå’Œä¸»å­˜ä¸­ç›¸åº”å•å…ƒæ•°æ®çš„ä¸€è‡´æ€§ï¼Œå…¶ç‰¹ç‚¹æ˜¯ç®€å•å¯é ï¼Œä½†ç”±äºCPUæ¯æ¬¡æ›´æ–°æ—¶éƒ½è¦å¯¹ä¸»å­˜å†™å…¥ï¼Œé€Ÿåº¦å¿…ç„¶å—å½±å“ã€‚

2. **Gepuffertes Durchschreibverfahren: (buffered write through policy)**

   Zur Milderung des Nachteils beim Durchschreibverfahren wird ein kleiner **Schreib-Puffer** verwendet, der **die zu schreibenden Daten temporaÌˆr aufnimmt.**

   Diese Daten werden dann **automatisch vom Cache- Controller in den Hauptspeicher uÌˆbertragen**, **waÌˆhrend der Prozessor parallel dazu mit weiteren Operationen fortfaÌˆhrt.**

   > 2ï¼ç¼“å†™å¼ï¼ˆpost writeï¼‰
   >
   > å³CPUåœ¨æ›´æ–°Cacheæ—¶ä¸ç›´æ¥æ›´æ–°ä¸»å­˜ä¸­çš„æ•°æ®ï¼Œè€Œæ˜¯æŠŠæ›´æ–°çš„æ•°æ®é€å…¥ä¸€ä¸ªç¼“å­˜å™¨æš‚å­˜ï¼Œåœ¨é€‚å½“çš„æ—¶å€™å†æŠŠç¼“å­˜å™¨ä¸­çš„å†…å®¹å†™å…¥ä¸»å­˜ã€‚åœ¨è¿™ç§æ–¹å¼ä¸‹ï¼ŒCPUä¸å¿…ç­‰å¾…ä¸»å­˜å†™å…¥è€Œé€ æˆçš„æ—¶å»¶ï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šæé«˜äº†é€Ÿåº¦ï¼Œä½†ç”±äºç¼“å­˜å™¨åªæœ‰æœ‰é™çš„å®¹é‡ï¼Œåªèƒ½é”å­˜ä¸€æ¬¡å†™å…¥çš„æ•°æ®ï¼Œå¦‚æœæ˜¯è¿ç»­å†™å…¥ï¼ŒCPUä»éœ€è¦ç­‰å¾…ã€‚

3. **RuÌˆckschreib-Verfahren: (write back policy)**

   Ein Datum wird von der CPU **nur in den Cachespeicher geschrieben** und durch ein **spezielles Bit** (*altered bit, modified bit, dirty bit*) gekennzeichnet.

   **Der Arbeitsspeicher wird nur geaÌˆndert, wenn ein so gekennzeichnetes Datum aus dem Cache verdraÌˆngt wird.**

   + Vorteil:
     auch Schreibzugriffe koÌˆnnen **mit der schnellen Cache-Zykluszeit abgewickelt** werden.

   + Nachteil:
     **Konsistenzprobleme** zwischen Cache- und Hauptspeicherspeicher .

   > 3ï¼å›å†™å¼ï¼ˆwrite backï¼‰
   >
   > å³CPUåªå‘Cacheå†™å…¥ï¼Œå¹¶ç”¨æ ‡è®°åŠ ä»¥æ³¨æ˜ï¼Œ**ç›´åˆ°Cacheä¸­è¢«å†™è¿‡çš„å—è¦è¢«è¿›å…¥çš„ä¿¡æ¯å—å–ä»£æ—¶ï¼Œæ‰ä¸€æ¬¡å†™å…¥ä¸»å­˜ã€‚**è¿™ç§æ–¹å¼è€ƒè™‘åˆ°å†™å…¥çš„å¾€å¾€æ˜¯ä¸­é—´ç»“æœï¼Œæ¯æ¬¡å†™å…¥ä¸»å­˜é€Ÿåº¦æ…¢è€Œä¸”ä¸å¿…è¦ã€‚å…¶ç‰¹ç‚¹æ˜¯é€Ÿåº¦å¿«ï¼Œé¿å…äº†ä¸å¿…è¦çš„å†—ä½™å†™æ“ä½œï¼Œä½†ç»“æ„ä¸Šè¾ƒå¤æ‚ã€‚

### Konsistenzprobleme

---

Ebenfalls koÌˆnnen andere Systemkomponenten Daten im Hauptspeicher aÌˆndern, **waÌˆhrend die CPU noch mit den alten Daten im Cachespeicher arbeitet.**

--> **aufwendige Verfahren bei der Cache-Steuerung zur Verhinderung solcher Inkonsistenzen sind erforderlich** 
(z. B. muss die **Cache-Steuerung uÌˆber jede DatenaÌˆnderung im Hauptspeicher informiert werden**).


### Begriffe

1. **Hit-Rate**

   Die **Hit-Rate** bezeichnet die **Trefferquote** im Cache:
   $$
   \text{Hit-Rate} = \text{Anzahl Treffer} / \text{Anzahl Zugriffe}
   $$
   

2. **mittlere Zugriffszeit**

   Die **mittlere Zugriffszeit** berechnet sich annaÌˆhernd wie folgt:
   $$
   t\_{Access} = (\text{Hit-Rate}) * t\_{Hit} + (1 - \text{Hit-Rate}) * t\_{Miss}
   $$

   - $t\_{Hit}$ : Zugriffszeit des Caches
   - $t\_{Miss}$ : Zugriffszeit ohne den Cache

### Aufbau eines Cache-Speichers (Folien14 s27)


#### Grob Struktur

Ein Cache-Speicher besteht aus zwei Speicher-Einheiten:

+ **Datenspeicher**:

  enthÃ¤lt die im Cache abgelegten **Daten**

+ **Adressspeicher**:

  enthÃ¤lt **die Adressen dieser Daten im Arbeitsspeicher**

#### Daten   

+ **Jeder Dateneintrag** besteht aus **einem ganzen Datenblock**(*ä¸€è¡Œ*) (**cache-line**, bis 64 Byte).

+ Mit jedem Datum, auf das der Prozessor zugreift, wird die **Umgebung miteingelagert** *(Hoffnung auf LokalitÃ¤t von Programmen)*.

+ Im **Adressspeicher** wird **die Basisadresse jedes Blocks** abgelegt

+ Jede Cache-Zeile enthÃ¤lt **ein (Adress-, Daten-)Paar und Statusbits**.

  **eine Cache-Zeile**:

  | Adressspeicherï¼ˆTagï¼‰                      | Statusbits    | Daten |      |
  | ------------------------------------------ | ------------- | ----- | ---- |
  | Adresse(Adress der Daten in HauptSpeicher) | valid + dirty | Daten |      |

+ Ein **(Daten)-Block** ist eine **zusammengehÃ¶rende Reihe
  von Speicherzellen (Cache-line).**

+ DazugehÃ¶rig wird ein **Adressetikett (Cache-Tag)ï¼Œ enthÃ¤lt die Adresse des aktuellen Blocks im Hauptspeicherï¼Œ** im
  **Adress-Speicher** ablegt.

+ Die **Statusbits** sagen aus, **ob die Daten im Cache gÃ¼ltig sind.**

#### Komparator

ermittelt, ob das zu einer auf dem Adressbus liegende Adresse gehÃ¶rende Datum auch **im Cache** abgelegt worden ist, durch **Adressvergleich mit den Adressen im Adressspeicher**

Dieser Adressvergleich muss **sehr schnell gehen (mÃ¶glichst in einem Taktzyklus)**, da sonst der Cachespeicher effektiv **langsamer** wÃ¤re als der Arbeitsspeicher.

### Drei Techniken fÃ¼r den Adressvergleich ô°‚---> 3 Cache-Typen:

#### 1. Voll-Assoziativer Cache(Folien14 s33 & s35)

**werden heute nur fÃ¼r sehr kleine auf dem Chip integrierte Caches mit 32 bis 128 EintrÃ¤gen verwendet.**

Vollparalleler Vergleich aller Adressen im Adressspeicher in einem einzigen Taktzyklus

+ **Vorteile**:

  + ein Datum kann an beliebiger Stelle im Cache abgelegt werden
  + Optimale Cache-Ausnutzung, vÃ¶llig freie Wahl der Strategie bei
    VerdrÃ¤ngungen

+ **Nachteile**:

  + **Hoher Hardwareaufwand** (fÃ¼r jede Cache-Zeile ein Vergleicher) ô°‚ 
    --> nur fÃ¼r **sehr kleine** Cachespeicher realisierbar

  + Die groÃŸe FlexibilitÃ¤t der Abbildungsvorschrift erfordert eine weitere Hardware, welche die Ersetzungsstrategie (**welcher Block soll Ã¼berschrieben werden, wenn der Cache voll ist**) realisiert.

  > å…¨ç›¸è¿æ˜ åƒæ–¹å¼Cache
  >
  > ä»»æ„ä¸»å­˜å•å…ƒçš„æ•°æ®æˆ–æŒ‡ä»¤å¯ä»¥å­˜æ”¾åˆ°Cacheçš„ä»»æ„å•å…ƒä¸­å»ï¼Œä¸¤è€…ä¹‹é—´çš„å¯¹åº”å…³ç³»ä¸å­˜åœ¨ä»»ä½•é™åˆ¶ã€‚
  >
  > + åœ¨Cacheä¸­ï¼Œç”¨äº**å­˜æ”¾æ•°æ®æˆ–æŒ‡ä»¤çš„é™æ€å­˜å‚¨å™¨SRAM**ç§°ä¸º **å†…å®¹Cacheï¼ˆDaten Cacheï¼ŒDaten Speicherï¼‰**
  > + ç”¨äºå­˜æ”¾**æ•°æ®æˆ–æŒ‡ä»¤åœ¨å†…å­˜ä¸­æ‰€åœ¨å•å…ƒçš„åœ°å€**çš„é™æ€å­˜å‚¨å™¨ç§°ä¸º **æ ‡è¯†Cacheï¼ˆtag Cacheï¼ŒTag Speicherï¼‰**
  >
  > å‡è®¾ä¸»å­˜åœ°å€æ˜¯16ä½ï¼Œæ¯ä¸ªå­˜å‚¨å•å…ƒ8ä½ï¼ˆ64k * 8 Organisationï¼‰ã€‚å‡è®¾å†…å®¹Cacheçš„å®¹é‡æ˜¯ 128 Byteï¼Œ å³æœ‰128ä¸ªå•å…ƒï¼ˆ128è¡Œï¼‰ï¼Œæ¯ä¸ªå•å…ƒï¼ˆæ¯è¡Œï¼‰çš„å®½åº¦ä¸º8ä½ï¼›è¡¨ç¤ºCacheï¼ˆTag Cacheï¼‰ä¹Ÿåº”è¯¥ç”±128ä¸ªå•å…ƒï¼ˆ128 è¡Œï¼‰ï¼Œä¸ºäº†å­˜æ”¾ä¸»å­˜å•å…ƒçš„åœ°å€ï¼ŒTag Cacheæ¯ä¸ªå•å…ƒï¼ˆæ¯è¡Œï¼‰çš„å®½åº¦åº”ä¸º16ä½ã€‚
  >
  > å½“CPUè¦è®¿é—®å†…å­˜æ—¶ï¼Œ å®ƒé€å‡ºçš„16ä½åœ°å€å…ˆä¸Tag Cacheä¸­çš„128ä¸ªåœ°å€æ¯”è¾ƒã€‚
  >
  >    + è‹¥æ‰€éœ€æ•°æ®æˆ–æŒ‡ä»¤çš„**åœ°å€åœ¨Tag Cacheä¸­**   
  >      --> å‘½ä¸­ï¼  
  >      --> ä»å†…å®¹Cacheä¸ä¹‹å¯¹åº”çš„å•å…ƒï¼ˆè¡Œï¼‰ä¸­è¯»å‡ºæ•°æ®æˆ–æŒ‡ä»¤ä¼ ç»™CPU

  >    + è‹¥æ‰€éœ€æ•°æ®æˆ–æŒ‡ä»¤çš„**åœ°å€ä¸åœ¨Tag Cacheä¸­**     
  >      --> ä»ä¸»å­˜ä¸­è¯»å‡ºæ‰€éœ€çš„æ•°æ®æˆ–æŒ‡ä»¤ä¼ ç»™CPUï¼ŒåŒæ—¶åœ¨Cacheä¸­å­˜ä¸€ä»½å‰¯æœ¬ï¼ˆ**å³å°†æ•°æ®æˆ–æŒ‡ä»¤å†™å…¥å†…å®¹Cacheï¼Œå¹¶å°†è¯¥æ•°æ®æˆ–æŒ‡ä»¤æ‰€åœ¨çš„å†…å­˜å•å…ƒçš„åœ°å€å†™å…¥Tag Cache**ï¼‰
  >
  >    æ˜¾ç„¶ï¼Œå¯¹äºå…¨ç›¸è¿æ˜ åƒCacheï¼ŒCacheä¸­å­˜å‚¨çš„æ•°æ®è¶Šå¤šï¼Œå‘½ä¸­ç‡è¶Šé«˜ã€‚ä½†å¢åŠ Cacheå®¹é‡å¸¦æ¥çš„é—®é¢˜æ˜¯ï¼šæ¯æ¬¡è®¿é—®å†…å­˜éƒ½è¦è¿›è¡Œå¤§é‡çš„åœ°å€æ¯”è¾ƒï¼Œæ—¢è€—æ—¶æ•ˆç‡ä¹Ÿä½ã€‚

  > å¦ä¸€æ–¹é¢ï¼Œè‹¥Cacheå®¹é‡å¤ªå°ï¼Œå¦‚16ä¸ªå•å…ƒï¼ˆè¡Œï¼‰ï¼Œç”±äºå‘½ä¸­ç‡å¤ªä½ï¼ŒCPUå°±è¦é¢‘ç¹çš„ç­‰å¾…æ“ä½œç³»ç»Ÿå°†Cacheä¸­çš„ä¿¡æ¯æ¢å…¥æ¢å‡ºï¼Œå› ä¸ºåœ¨å‘Cacheä¸­å†™å…¥æ–°ä¿¡æ¯ä¹‹å‰ï¼Œå¿…é¡»å°†Cacheä¸­å·²æœ‰çš„ä¿¡æ¯ä¿å­˜åœ¨ä¸»å­˜ä¸­ã€‚

#### 2. Direct-mapped-Cacheï¼ˆFolien14 s37ï¼Œ38 & 41ï¼‰


Beim Direct Mapped Cache erhÃ¤lt jede Stelle des Hauptspeichers einen **eindeutigen und festen Platz im Cache**ï¼ˆkommt auf den **Index** anï¼‰

+ **Nachteil**

  StÃ¤ndige Konkurrenz der BlÃ¶cke (z. B. 0, 64, 128,...), **obwohl andere BlÃ¶cke im Cache frei sein kÃ¶nnen.**

  > å› ä¸ºå†…å­˜ä¸­çš„æŸä¸€ä¸ªå•å…ƒå®šä½å¯¹åº”Cacheä¸­çš„ä¸€ä¸ªBlockçš„åœ°å€æ˜¯ç”±Indexï¼ˆåœ°å€çš„ä½nä½éƒ¨åˆ†å†³å®šï¼‰ï¼Œ å³ å†…å­˜ä¸­çš„æŸä¸€ä¸ªå•å…ƒçš„ä½nä½åœ°å€ = Cacheä¸­çš„ä¸€ä¸ªCache Zeileçš„åœ°å€ã€‚ è¿™æ„å‘³ç€ï¼Œåªè¦å†…å­˜ä¸­çš„ä¸¤ä¸ªä¸åŒå•å…ƒçš„åœ°å€çš„ä½nä½ç›¸åŒï¼Œå°±ä¼šå®šä½åˆ°åŒä¸€ä¸ªCache Zeileï¼Œå°½ç®¡å®ƒä»¬çš„é«˜ä½åœ°å€å¹¶ä¸ç›¸åŒã€‚

+ **Vorteil**

  **Geringer Hardwareaufwand fÃ¼r die Adressierung**, da nur ein Vergleicher fÃ¼r alle Tags benÃ¶tigt wird. 

+ **Merkmale**

  + **Einfache** Hardware-Realisierung (nur **ein Vergleicher** und **ein Tag-Speicher**)  

  + Der **Zugriff** erfolgt **schnell**, weil das Tag-Feld **parallel** mit dem zugehÃ¶rigen Block gelesen werden kann

  + Es ist **keine Ersetzungsstrategie erforderlich**, weil die direkte Zuordnung keine Alternativen zulÃ¤sst

  + Auch wenn an anderer Stelle im Cache noch Platz ist, erfolgt **wegen der direkten Zuordnung eine Ersetzung**

  + Bei einem abwechselnden Zugriff auf SpeicherblÃ¶cke, deren Adressen den **gleichen Index-Teil** haben, erfolgt **laufendes Ãœberschreiben** des gerade geladenen Blocks. 

> ç›´æ¥æ˜ åƒCacheä¸å…¨ç›¸è¿æ˜ åƒCacheå®Œå…¨ç›¸åï¼Œå®ƒåªéœ€è¦åšä¸€æ¬¡åœ°å€æ¯”è¾ƒå³å¯ç¡®å®šæ˜¯å¦å‘½ä¸­ã€‚
> åœ¨è¿™ç§Cacheç»“æ„ä¸­ï¼Œåœ°å€åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼š
>
>   + **ç´¢å¼•ï¼ˆIndexï¼‰ï¼š åœ°å€çš„ä½ä½éƒ¨åˆ†ï¼Œç›´æ¥ä½œä¸ºå†…å®¹Cacheçš„åœ°å€ï¼Œå®šä½åˆ°å†…å®¹Cacheçš„ç›¸åº”å•å…ƒã€‚**
>
>   + **æ ‡è¯†ï¼ˆTagï¼‰ï¼š å­˜å‚¨åœ¨æ ‡è¯†Cacheä¸­**ã€‚
>
> ä¾‹ï¼šå‡è®¾CPUé€å‡ºçš„å†…å­˜åœ°å€ä¸º16ä½ï¼ŒA0 - A10ä¸ºç´¢å¼• ï¼Œ A11 - A15ä¸ºæ ‡è¯†ã€‚
>
> ç°åœ¨CPUç»™å‡ºçš„åœ°å€æ˜¯ E898H ï¼ˆ`1110 1000 1001 1000`ï¼‰ï¼Œåˆ™`000 1001 1000`ä¸ºç´¢å¼•ï¼Œ `11101`ä¸ºæ ‡è¯†ã€‚
>
> 1. ç´¢å¼•`000 1001 1000`ä½œä¸ºåœ°å€ï¼Œç”¨ä½œåœ¨å†…å®¹Cacheå’Œæ ‡è¯†Cacheä¸­å„ç¡®å®šä¸€ä¸ªå•å…ƒï¼ˆè¡Œï¼‰ï¼Œå³è¿™ä¸¤ä¸ªå•å…ƒéƒ½æ˜¯ç”±`000 1001 1000`è¯‘ç å¾—åˆ°çš„ï¼ˆå°±æ˜¯ç”¨`000 1001 1000`ç¡®å®šä¸€ä¸ªCache Zeileï¼‰ã€‚è¿™æ ·åœ¨å†…å®¹Cacheä¸­ï¼Œå°±ç¡®å®šäº†ä¸€ä¸ªå­˜æ”¾æ•°æ®çš„å•å…ƒï¼ˆè¡Œï¼‰ï¼›åŒæ—¶åœ¨Cacheä¸­ï¼Œä¹Ÿç¡®å®šäº†ä¸€ä¸ªå­˜æ”¾æ ‡è¯†çš„å•å…ƒï¼ˆè¡Œï¼‰ï¼Œ**æ­¤æ—¶å¹¶ä¸è¯»å‡ºæ•°æ®**ã€‚ 
>
> 2. **æ¥ç€æ‹¿æ ¹æ®`000 1001 1000`ç¡®å®šçš„æ ‡è¯†Cacheä¸­å­˜æ”¾çš„æ ‡è¯†ä¸CPUç»™å‡ºçš„åœ°å€ä¸­çš„æ ‡è¯†`11101` æ¯”è¾ƒ**ï¼š
>    + ç›¸ç­‰ --> å‘½ä¸­ï¼å°†å†…å®¹Cacheä¸­å­˜æ”¾çš„æ•°æ®è¯»å…¥CPUã€‚
>
>    + ä¸ç›¸ç­‰ --> CPUè¦ç­‰å¾…å­˜å‚¨å™¨æ§åˆ¶å™¨å°†åœ°å€ä¸º E898H ä¸»å­˜å•å…ƒçš„å†…å®¹è¯»å…¥ï¼ŒåŒæ—¶åœ¨Cacheå¤åˆ¶ä¸€ä»½å‰¯æœ¬ï¼ˆåŒ…æ‹¬æ ‡è¯†ï¼‰ï¼Œä¾›CPUå°†æ¥ä½¿ç”¨ã€‚
>
> è¦æ³¨æ„ï¼šç´¢å¼•å·`000 1001 1000`åªå¯¹åº”è¿™ä¸€ä¸ªCacheå•å…ƒï¼Œä½†å¯èƒ½æœ‰32ï¼ˆ2 ^ 5 = 32ï¼‰
> ç§æ ‡è¯†ï¼Œå³Tag Cacheä¸­çš„äº”ä½æ ‡è¯†æœ‰å¯èƒ½å¯¹åº”è¿™32ä¸ªåœ°å€ä¸­çš„æŸä¸€ä¸ªï¼Œä»`0000 1000 1001 1000`åˆ°`1111 1000 1001 1000`ã€‚åªè¦æ ‡è¯†ä¸åŒ¹é…ï¼ˆ**å³æ ¹æ®ç´¢å¼•æ‰¾åˆ°çš„Tag Cacheä¸­çš„é‚£ä¸€è¡Œçš„æ ‡è¯†** ä¸ **CPUç»™å‡ºçš„åœ°å€ä¸­çš„æ ‡è¯†**ï¼ˆåœ¨è¿™é‡Œæœ‰32ç§å¯èƒ½æ€§ï¼‰ *ä¸ç›¸ç­‰*ï¼‰ï¼Œå°±è¡¨ç¤ºCacheæœªå‘½ä¸­ã€‚
>
>
> **ç¼ºç‚¹ï¼š**
> ç›´æ¥æ˜ åƒæ–¹å¼çš„Cacheå®è´¨ä¸Šè¦æ±‚ ä¸»å­˜çš„æŸä¸€ä¸ªå•å…ƒï¼Œæ¯”å¦‚è¯´æ˜¯Aå•å…ƒï¼ˆå‡è®¾åœ°å€ä¸º `0000 0000 1001 1000`ï¼‰åªèƒ½ä¸Cacheä¸­çš„ä¸€ä¸ªç‰¹å®šå•å…ƒï¼ˆè¡Œï¼‰ï¼ˆåœ°å€ä¸º `000 1001 1000`ï¼ˆç´¢å¼•ï¼‰ï¼‰å‘ç”Ÿè”ç³»ï¼Œè€Œä¸èƒ½ä¸å…¶ä»–Cacheå•å…ƒå‘ç”Ÿè”ç³»ã€‚ 
>
> --> ä¸»å­˜çš„ä½11ä½åœ°å€ï¼ˆA0 - A10ï¼‰å†³å®šäº†ä¸å®ƒå‘ç”Ÿå…³è”çš„é‚£ä¸ªCacheå•å…ƒçš„åœ°å€ã€‚
>
> å¦‚æœæ­¤æ—¶è¿™ä¸ªCacheå•å…ƒæ­£è¢«å…¶ä»–ä½11ä½åœ°å€ä¸Aç›¸åŒçš„å†…å­˜å•å…ƒæ‰€å ç”¨ï¼Œæ¯”å¦‚è¯´Bå•å…ƒï¼ˆå‡è®¾Båœ°å€ä¸º `0000 1000 1001 1000`,æ³¨æ„Aå’ŒBçš„ä½11ä½åœ°å€ç›¸åŒï¼ˆIndexç›¸åŒï¼ŒTagä¸åŒï¼‰ï¼‰ã€‚é‚£ä¹ˆå³ä½¿å½“æ—¶Cacheä¸­å­˜åœ¨å…¶ä»–ç©ºé—²çš„å•å…ƒï¼ŒAå•å…ƒçš„å†…å®¹ä¹Ÿä¸èƒ½è¢«æ”¾åˆ°Cacheä¸­ã€‚
>
> è¿™å°±æ˜¯ç›´æ¥æ˜ åƒCacheçš„ç¼ºç‚¹ï¼š**å°½ç®¡åœ°å€æ¯”è¾ƒçš„æ¬¡æ•°æ˜¯ä¸€æ¬¡ï¼Œä½† ä¸åŒçš„å†…å­˜å•å…ƒå´è‚¯æ©å…±æœ‰ç›¸åŒçš„Cacheç´¢å¼•ï¼Œä¸åŒçš„Cacheæ ‡è¯†ä½¿å¾—Cacheä»æœªå‘½ä¸­ï¼Œä»éœ€è®¿é—®ä¸»å­˜ã€‚**

#### 3. n-way-set-assoziativer Cache

---

####Kompromiss zwischen direct-mapped-Cache und vollassoziativen Cache.

Zum Auffinden eines Datums mÃ¼ssen **alle n Tags mit demselben Index parallel verglichen werden**

--------> der Aufwand **steigt** mit der Zahl n;
fÃ¼r groÃŸe n nÃ¤hert sich der Aufwand den voll-assoziativen Caches

+ Verbesserte Trefferrate, da hier eine Auswahl mÃ¶glich ist (der zu verdrÃ¤ngende Eintrag kann unter n ausgewÃ¤hlt


#### Ersetzungssstrategie(notwendig nur bei voll- oder n-fach satzassoziativer Cachespeicherorganisation)

Ersetzungsstrategie gibt an, welcher Teil des Cachespeichers nach einem Cache-Miss durch eine neu geladene Speicherportion Ã¼berschrieben wird.

+ **Zyklisch** (der zuerst eingelagerte Eintrag wird auch wieder
  verdrÃ¤ngt, FIFO-Strategie)

+ **LRU-Strategie** (least recently used) der am lÃ¤ngsten nicht mehr benutzte Eintrag wird entfernt.

+ **ZufÃ¤llig** (durch Zufallsgenerator)

Meist wird die sehr einfache Strategie gewÃ¤hlt:
Die am lÃ¤ngsten nicht benutzte Speicherportion wird ersetzt (**LRU-Strategie, Least Recently Used**).

> ç»„ç›¸è¿æ˜ åƒCache
>
> ç»„ç›¸è¿æ˜ åƒCache**æ˜¯ä»‹äºå…¨ç›¸è¿æ˜ åƒå’Œç›´æ¥æ˜ åƒCacheä¹‹é—´**çš„ä¸€ç§ç»“æ„ã€‚åœ¨**ç›´æ¥æ˜ åƒCache**ä¸­ï¼Œæ¯ä¸ªç´¢å¼•åœ¨Cacheåªèƒ½å­˜æ”¾**ä¸€ä¸ª**æ ‡è¯†ã€‚è€Œåœ¨**ç»„ç›¸è¿æ˜ åƒ**ä¸­ï¼Œå¯¹åº”æ¯ä¸ªç´¢å¼•ï¼Œåœ¨Cacheä¸­**èƒ½å¤Ÿå­˜æ”¾çš„æ ‡è¯†æ•°é‡å¢åŠ äº†ï¼Œä»è€Œå¢åŠ äº†å‘½ä¸­ç‡**ã€‚
>
> ä¾‹å¦‚åœ¨2è·¯ç»„ç›¸è¿æ˜ åƒCacheä¸­ï¼Œæ¯ä¸ªç´¢å¼•åœ¨Cacheä¸­èƒ½å­˜æ”¾**ä¸¤ä¸ª**æ ‡è¯†ï¼Œå³**åœ¨Cacheä¸­å¯ä»¥å­˜æ”¾ä¸¤ä¸ªå…·æœ‰ç›¸åŒç´¢å¼•çš„å†…å­˜çš„å•å…ƒçš„å†…å®¹**ï¼ˆè¿™ä¸¤ä¸ªå†…å­˜å•å…ƒåœ°å€çš„ä½ä½éƒ¨åˆ†ï¼ˆIndex-teilï¼‰ç›¸åŒï¼Œä½†é«˜ä½éƒ¨åˆ†ï¼ˆTagï¼‰ä¸åŒï¼‰ã€‚
>
> ä¾‹ï¼š
>
> CPUè¯·æ±‚è®¿é—®åœ°å€ä¸º **4518H (`0100 0101 0001 1000`)** ä¸»å­˜å•å…ƒçš„å†…å®¹ï¼Œåœ¨2è·¯ç»„ç›¸è¿æ˜ åƒCacheä¸­ï¼Œä¸ç´¢å¼•`01 0001 1000`å¯¹åº”çš„æ ‡è¯†å¯ä»¥æœ‰2ä¸ªï¼ŒCacheç”µè·¯å°†2ä¸ªæ ‡è¯†åˆ†åˆ«ä¸`0100 01`æ¯”è¾ƒï¼š
>
>   + è‹¥å…¶ä¸­æœ‰ä¸€ä¸ªåŒ¹é…ï¼Œåˆ™å‘½ä¸­ --> å°†ç´¢å¼•`01 0001 1000`æ‰€å¯¹åº”çš„æ•°æ®è¯»å…¥CPUä¸­ã€‚
>
>   + è‹¥ä¸¤ä¸ªæ ‡è¯†ä¸­ä»»ä½•ä¸€ä¸ªéƒ½ä¸æ˜¯`0100 01`çš„è¯ --> æœªå‘½ä¸­ --> Cacheæ§åˆ¶å™¨ä»å†…å­˜ä¸­è¯»å…¥æ‰€éœ€å†…å®¹ï¼ŒåŒæ—¶åœ¨Cacheä¸­å¤‡ä»½ä¸€ä»½å‰¯æœ¬ã€‚
>
> ç±»ä¼¼çš„ï¼Œåœ¨4è·¯ç»„ç›¸è¿æ˜ åƒCacheä¸­ï¼Œå‡è®¾CPUè¦è®¿é—®çš„åœ°å€ä¹Ÿæ˜¯**4518H (`0100 0101 0001 1000`)**ï¼Œéœ€è¦æŠŠå››ä¸ªæ ‡è¯†ä¸ `0100 010` æ¯”è¾ƒã€‚ä¸2è·¯ç›¸æ¯”ï¼Œ4è·¯Cacheçš„å‘½ä¸­ç‡åˆæé«˜äº†50%ã€‚
>
> ä»ä¾‹å­ä¸­å¯ä»¥çœ‹å‡ºï¼Œåœ¨ç»„ç›¸è¿æ˜ åƒCacheä¸­ï¼Œæ¯”è¾ƒçš„æ¬¡æ•°ä¸ç›¸å…³è”çš„ç¨‹åº¦æœ‰å…³ã€‚
> **nè·¯ç»„ç›¸è¿æ˜ åƒæ¯”è¾ƒæ¬¡æ•°ä¸ºn**
> **ç»„çš„æ•°ç›®è¶Šå¤šï¼Œæ€§èƒ½è¶Šé«˜ã€‚**ä½†ç”¨ä½œæ ‡è¯†Cacheçš„SRAMå®¹é‡ä¹Ÿç›¸åº”å¢åŠ äº†ï¼Œä»è€ŒåŠ å¤§äº†æˆæœ¬ã€‚8ã€16è·¯ç»„ç›¸è¿æ˜ åƒCacheä¸­æ‰€å¢åŠ çš„æˆæœ¬ä¸æé«˜çš„å‘½ä¸­ç‡ç›¸æ¯”æ˜¯ä¸åˆ’ç®—çš„ï¼›è€Œä¸”å¢åŠ ç»„çš„æ•°ç›®ï¼Œä¹Ÿå¢åŠ äº†Tagçš„æ¯”è¾ƒæ¬¡æ•°ã€‚**ç›®å‰ç»å¤§å¤šæ•°Cacheç³»ç»Ÿå®ç°çš„æ—¶4è·¯**ã€‚
>
> 

### Ursachen fÃ¼r die Fehlzugriffe

---

1. **Erstzugriff (compulsory - obligatorisch)**: 

   Beim **ersten Zugriff** auf einen Cache-Block befindet sich dieser noch nicht im Cache- Speicher und **muss erstmals geladen werden** 

   --> **Kaltstartfehlzugriffe (cold start misses)** oder **Erstbelegungsfehlzugriffe (first reference misses).**

2. **KapazitÃ¤t (capacity)**: 

   Falls der Cache-Speicher nicht alle benÃ¶tigten Cache-BlÃ¶cke aufnehmen kann, **mÃ¼ssen Cache-BlÃ¶cke verdrÃ¤ngt und eventuell spÃ¤ter wieder geladen werden**.

3. **Konflikt (conflict) :** 

   treten nur bei **direkt abgebildeten** oder **satzassoziativen Cache-Speichern beschrÃ¤nkter GrÃ¶ÃŸe** auf

   ein Cache-Block wird verdrÃ¤ngt und spÃ¤ter wieder geladen, falls **zu viele Cache-BlÃ¶cke auf denselben Satz abgebildet werden** 

   --> **Kollisionsfehlzugriffe (collision misses)** oder **Interferenzfehlzugriffe (interference misses).**

   

### Erzielbare Cache-Trefferquoten

---

1. **Je grÃ¶ÃŸer** der Cachespeicher, **desto grÃ¶ÃŸer** die Trefferquote

   > Eine Cache-Trefferquote von circa **94%** kann bei einem
   > **64 kByte** groÃŸen Cachespeicher erreicht werden

2. **Getrennte** Daten- und Befehls-Cachespeicher sind bei sehr kleinen CachespeichergrÃ¶ÃŸen vorteilhaft

3. Bei CachespeichergrÃ¶ÃŸen **ab 64 KByte** sind **Direct Mapped Cachespeicher** mit ihrer Trefferquote nur **wenig schlechter als Cachespeicher mit AssoziativitÃ¤t 2 oder 4.**



**Voll-assoziative Cachespeicher werden heute nur fÃ¼r sehr kleine auf dem Chip integrierte Caches mit 32 bis 128 EintrÃ¤gen verwendet.**

**Bei grÃ¶ÃŸeren Cachespeichern findet sich zur Zeit ein Trend zur Direct Mapped Organisation oder 2 - 8 fach assoziativer Organisation.**  

### Anbindung des Caches an den Systembus (Folien15 s35) 

---

#### 1. Cache-Controller

#### Cache-Controller =  Tag-RAM + Steuerung + Tag-Komparator

+ **auf einem Chip integriert**(Da dieser sehr schnell sein muÃŸ)

+ Cache-Controller **Ã¼bernimmt die Steuerung der Treiber zum Systembus** (Systembuszugriff **nur bei Cache-Miss**, sonst ist der Systembus fÃ¼r andere Komponenten frei), sowie der Systembussignale zur EinfÃ¼gung von Wartezyklen bei Cache-Miss (READY, HOLD, HOLDA, ...)


#### 2. Cachespeicher 

selbst ist **seperat** mit **SRAM-Bausteinen aufgebaut.**


### Verwendung mehrerer Caches(Folien15 s34)

---


#### 1. First-Level-Cache (On-Chip-Cache)

HÃ¤ufig **getrennte** On-Chip-Caches**(Harvard-Architektur**) : 

+ **Befehlscache** 

  fÃ¼r die Befehle 

+ **Datencache** 

  fÃ¼r die Daten.

  **paralleler Zugriff auf Programm und Daten**

**Zusammenfassen:**

+ integriert auf dem Prozessorchip 


+ Sehr **kurze Zugriffszeiten** (**wie** die der prozessorinternen **Register**)


+ Aus technologischen GrÃ¼nden **begrenzte KapazitÃ¤t**

#### 2. Secondary- Level-Cache (On-Board-Cache, 64 - 1024 KByte groÃŸ)  


+ AuÃŸerhalb des Prozessor-Chips(**prozessorextern**)

+ grÃ¶ÃŸer als On-Chip-Cache

+ Der Secondary-Level-Cache kann **parallel zum Hauptspeicher an den Bus angeschlosssen werden (Look-Aside-Cache)**. Er sorgt dafÃ¼r, dass bei einem First-Level-Cache-Miss **die Daten schnell nachgeladen** werden kÃ¶nnen


### Cache-KohÃ¤renzproblem

---

+ **GÃ¼ltigkeitsproblem**, das beim Zugriff mehrerer Verarbeitungselemente (z. B. Prozessoren) auf Speicherworte des Hauptspeichers entsteht.

+ **KohÃ¤renz** bedeutet das **korrekte Voranschreiten des Systemzustands** durch ein abgestimmtes Zusammenwirken der EinzelzustÃ¤nde.

+ Im Zusammenhang mit dem Cache muss das System dafÃ¼r sorgen, dass **immer die aktuellsten Daten und nicht veraltete Daten aus dem Cache gelesen werden**.

**Ein System ist konsistent, wenn alle Kopien eines Datums im Hauptspeicher und den verschiedenen Cachespeichern identisch sind. Dadurch ist auch die KohÃ¤renz sichergestellt, jedoch entsteht ein hoher Aufwand.**

--> konsistent **Datums in Hauptspeicher** und **deren Kopien in Cache** muss **identisch** sein!!!


> åœ¨è®¡ç®—æœºç§‘å­¦ä¸­ï¼Œç¼“å­˜ä¸€è‡´æ€§ï¼ˆè‹±è¯­ï¼šCache coherenceï¼Œæˆ–cache coherencyï¼‰ï¼Œåˆè¯‘ä¸ºç¼“å­˜è¿è´¯æ€§ã€ç¼“å­˜åŒè°ƒï¼Œæ˜¯æŒ‡ä¿ç•™åœ¨é«˜é€Ÿç¼“å­˜ä¸­çš„å…±äº«èµ„æºï¼Œä¿æŒæ•°æ®ä¸€è‡´æ€§çš„æœºåˆ¶ã€‚

> åœ¨ä¸€ä¸ªç³»ç»Ÿä¸­ï¼Œå½“è®¸å¤šä¸åŒçš„è®¾å¤‡å…±äº«ä¸€ä¸ªå…±åŒå­˜å‚¨å™¨èµ„æºï¼Œåœ¨é«˜é€Ÿç¼“å­˜ä¸­çš„æ•°æ®ä¸ä¸€è‡´ï¼Œå°±ä¼šäº§ç”Ÿé—®é¢˜ã€‚è¿™ä¸ªé—®é¢˜åœ¨æœ‰æ•°ä¸ªCPUçš„å¤šå¤„ç†æœºç³»ç»Ÿä¸­ç‰¹åˆ«å®¹æ˜“å‡ºç°ã€‚

> ç¼“å­˜ä¸€è‡´æ€§å¯ä»¥åˆ†ä¸ºä¸‰ä¸ªå±‚çº§ï¼š
>
> + åœ¨è¿›è¡Œæ¯ä¸ªå†™å…¥è¿ç®—æ—¶éƒ½ç«‹åˆ»é‡‡å–æªæ–½ä¿è¯æ•°æ®ä¸€è‡´æ€§
> + æ¯ä¸ªç‹¬ç«‹çš„è¿ç®—ï¼Œå‡å¦‚å®ƒé€ æˆæ•°æ®å€¼çš„æ”¹å˜ï¼Œæ‰€æœ‰è¿›ç¨‹éƒ½å¯ä»¥çœ‹åˆ°ä¸€è‡´çš„æ”¹å˜ç»“æœ
> + åœ¨æ¯æ¬¡è¿ç®—ä¹‹åï¼Œä¸åŒçš„è¿›ç¨‹å¯èƒ½ä¼šçœ‹åˆ°ä¸åŒçš„å€¼ï¼ˆè¿™ä¹Ÿå°±æ˜¯æ²¡æœ‰ä¸€è‡´æ€§çš„è¡Œä¸ºï¼‰

<br>
<br>

### Bus-SchnÃ¼ffeln (Bus-Snooping)

---

In **Mehrprozessorsystemen**, bei denen mehrere Prozessoren mit lokalen Cachespeichern an einen **gemeinsamen Bus/Hauptspeicher** angeschlossen sind, verwendet man das sogenannte **Bus-SchnÃ¼ffeln**

Die **SchnÃ¼ffel-Logik** jedes Prozessors **hÃ¶rt am Bus die Adressen mit**, die **die anderen Prozessoren** auf den Bus legen. Die **Adressen auf dem Bus** werden **mit den Adressen, der im Cache gespeicherten** Daten, **verglichen**

Bei **AdressÃ¼bereinstimmung** am Bus geschieht folgendes:

+ **Schreibzugriff**

  Wenn ein Schreibzugriff auf dieselbe Adresse vorliegt, dann wird der im Cache gespeicherte Cacheblock fÃ¼r **â€ungÃ¼ltigâ€œ** erklÃ¤rt **(Write- Invalidate-Verfahren)**, oder mit **aktualisiert (Write-Update- Verfahren).**

+ **Lesezugriff**

  Wenn ein Lesezugriff auf dieselbe Adresse mit einer **modifizierten Datenkopie** im Cachespeicher festgestellt wird, dann legt der Cache- Controller ein **Snoop Status Signal (SSTAT)** auf den Bus.

  1. Der Prozessor, der die Adresse auf den Bus gelegt hat, unterbricht seine Bustransaktion.

  2. Der â€schnÃ¼ffelndeâ€œ Cache-Controller Ã¼bernimmt den Bus und schreibt den betreffenden Cacheblock in den Hauptspeicher.

  3. Dann wird die ursprÃ¼ngliche Bustransaktion erneut durchgefÃ¼hrt.

> ä¸ªäººç†è§£ï¼š
>
> å¤„ç†å™¨ä¸Šçš„SchnÃ¼ffel-Logikç›‘å¬ç€Busä¸Šçš„åˆ«çš„å¤„ç†å™¨æ”¾ä¸Šå»çš„åœ°å€ï¼ŒBusä¸Šçš„åœ°å€ä¼šè¢«æ‹¿æ¥è·ŸCacheä¿å­˜çš„åœ°å€æ¯”è¾ƒ
>
> è‹¥Busä¸­çš„Adresseå’ŒCacheä¸­Tag Speicherä¸­çš„æŸä¸ªåœ°å€ç›¸åŒã€‚
>
> è€Œä¸”ç°åœ¨å¤šæ ¸å¤„ç†å™¨çš„æŸä¸€ä¸ªå¤„ç†å™¨å¯¹Busä¸Šçš„è¿™ä¸ªAdressæ‰§è¡ŒSchreibzugriff 
>
> --> Cacheä¸­çš„è¿™ä¸ªåœ°å€çš„å†…å­˜å•å…ƒçš„å†…å®¹å°†è¢«æ”¹å˜ 
>
> --> é€ æˆäº†ï¼šåŒä¸€ä¸ªåœ°å€ï¼ŒHauptspeicherä¸­çš„å†…å®¹å’ŒCacheä¸­çš„å†…å®¹ä¸ä¸€è‡´ï¼ˆKohÃ¤renz kaputtï¼‰ 
>
> --> æ‰€ä»¥è¿™ä¸ªåœ°å€å¯¹åº”çš„Cacheä¸­çš„Blockï¼ˆCache-Zeileï¼‰è¦æ ‡ä¸Šâ€ungÃ¼ltigâ€œ(Write- Invalidate-Verfahren) æˆ–è€… aktualisiert (Write-Update- Verfahren) æ¥è¡¨æ˜
> æ•°æ®ä¸ä¸€è‡´
>
> --> è¦è®¿é—®è¿™ä¸ªåœ°å€çš„å¤„ç†å™¨ï¼ˆå·²ç»æŠŠè¿™ä¸ªåœ°å€æ”¾åˆ°åœ°å€æ€»çº¿Adressbusï¼‰ç»ˆæ­¢è¿™æ¬¡Transaktion
>
> --> Cache Controlleræ¥ç®¡Busï¼ŒæŠŠç›¸å…³çš„è¢«ä¿®æ”¹çš„Blockï¼ˆCache Zeileï¼‰å†™åˆ°å†…å­˜ä¸­ç›¸åŒåœ°å€å¯¹åº”çš„å†…å­˜å•å…ƒã€‚
>
> --> ç„¶ååˆšæ‰è¢«è·³è¿‡çš„BusTransaktioné‡æ–°æ‰§è¡Œã€‚

## Fragen, die sich ein Speicherhierarchie-Designer stellen mussã€‚


### 1.Block-Abbildungsstrategie

#### Wohin kann ein Block abgebildet werden? 

+ Voll-assoziativ

+ Satz-Assoziativ

+ Direct-Mapped

### 2.Block-Identifikation

#### Wie kann ein Block gefunden werden?

+ Tag/Block

### 3.Block-Ersetzungsstrategie

#### Welcher Block soll bei einem Miss ersetzt werden?

+ Random

+ FIFO

+ LRU


### 4.Schreibe-Strategie 

#### Was passiert bei einem Schreibzugriff?  

+ Durchschreibverfahren(write through policy)

+ Gepuffertes Durchschreibverfahren: (buffered write through policy)

+ RÃ¼ckschreib-Verfahren: (write back policy)

## Cache-Steuerung (Cache controller)

Cache-Steuerung prÃ¼ft, ob

+ **Bedingung 1**: 

  Der zur Speicheradresse gehÃ¶rende Hauptspeicherinhalt als Kopie im Cache steht

+ **Bedingung 2**:

  Dieser Cache-Eintrag durch das GÃ¼ltigkeits-Bit **(Valid- Bit)** als gÃ¼ltig gekennzeichnet ist

PrÃ¼fung fÃ¼hrt zu einem **Cache-Treffer** oder zu einem **Fehlzugriff**.

**Cache-Fehlzugriff (Cache-miss)**: eine der beiden Bedingungen ist nicht erfÃ¼llt.

+ **Lesezugriffe (read miss)**, Dann:

  1.  Lesen des Datums aus dem Hauptspeicher und Laden des Cache-Speichers
  2.  Kennzeichnen der Cache-Eintrag als **gÃ¼ltig** (V-Bit setzen)
  3.  Speichern der Adressinformation im Adress-Speicher des Cache-Speichers

+ **Schreibzugriffe (write miss)**

  Aktualisierungsstrategie bestimmt, ob

  + der entsprechende Block in den Cache geladen und dann **mit dem zu schreibenden Datum aktualisiert** wird 

  oder

  + nur der Cache aktualisiert wird und **der Hauptspeicher unverÃ¤ndert** bleibt


**3 Strategie :** 

  1. Durchschreibverfahren (write through)

  2. Gepuffertes Schreibverfahren (write buffer)

  3. RÃ¼ckschreibverfahren (write back)  