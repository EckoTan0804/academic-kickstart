---
# Basic info
title: "Multiprozessoren mit gemeinsamem Speicher"
date: 2020-07-29
draft: false
type: docs # page type
authors: ["admin"]
tags: ["Vorlesung", "Zusammenfassung", "Rechnerstruktur"]
categories: ["Computer Structure"]
toc: true # Show table of contents?

# Advanced settings
profile: false  # Show author profile?

reading_time: true # Show estimated reading time?
summary: ""
share: false  # Show social sharing links?
featured: true
lastmod: true

comments: false  # Show comments?
disable_comment: true
commentable: false  # Allow visitors to comment? Supported by the Page, Post, and Docs content types.

editable: false  # Allow visitors to edit the page? Supported by the Page, Post, and Docs content types.

# Optional header image (relative to `static/img/` folder).
header:
  caption: ""
  image: ""

# Menu
menu: 
    rechner-struktur:
        parent: multiprozessoren
        weight: 6

# Prev/next pager order (if `docs_section_pager` enabled in `params.toml`)
weight: 35
---

<img src="https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/æˆªå±2020-07-29%2010.53.01.png" alt="æˆªå±2020-07-29 10.53.01" style="zoom:80%;" />

- **UMA**: **Uniform Memory Access**
  - Beispiel: **symmetrischer Multiprozessor (SMP)**: *Gleichberechtigter* Zugriff der Prozessoren auf die Betriebsmittel

## Speicherhierarchie

<img src="https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/æˆªå±2020-07-29%2010.55.55.png" alt="æˆªå±2020-07-29 10.55.55" style="zoom:80%;" />

- AusnuÌˆtzen der **LokalitaÌˆtseigenschaft** von Programmen 
- **Kompromiss** zwischen Preis und LeistungsfaÌˆhigkeit
- Speicherkomponenten mit **unterschiedlichen Geschwindigkeiten und KapazitaÌˆten**

### Cache Speicher

- Pufferspeicher mit **schnellem** Zugriff

- Anwendung

  - Pufferspeicher zwischen Hauptspeicher und Prozessor
  - Stellt die waÌˆhrend einer ProgrammausfuÌˆhrung jeweils aktuellen Hauptspeicherinhalte fuÌˆr Prozessorzugriffe als **Kopien** moÌˆglichst schnell zur VerfuÌˆgung.

- Aktualisierungsstrategie

  <img src="https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/æˆªå±2020-07-29%2010.58.40.png" alt="æˆªå±2020-07-29 10.58.40" style="zoom:80%;" />

  - Write-through with no-write allocation

    <img src="https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/800px-Write-through_with_no-write-allocation.svg.png" alt="img" style="zoom: 67%;" />

  - Write-back with write allocation

    <img src="https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/800px-Write-back_with_write-allocation.svg.png" alt="img" style="zoom: 80%;" />

## GuÌˆltigkeitsproblem

- wenn diese Prozessoren jeweils unabhaÌˆngig voneinander auf SpeicherwoÌˆrter des Hauptspeichers zugreifen koÌˆnnen.
- Mehrere Kopien des gleichen Speicherwortes muÌˆssen miteinander in Einklang gebracht werden.

Eine Cache-Speicherverwaltung heiÃŸt **cache-kohaÌˆrent**, wenn ein Lesezugriff immer den Wert des zeitlich letzten Schreibzugriffs auf das entsprechende Speicherwort liefert.

## Cache-KohaÌˆrenz-Problem

### 1.Fall: I/O-Problem

<img src="https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/æˆªå±2020-07-29 11.06.35.png" alt="æˆªå±2020-07-29 11.06.35" style="zoom:80%;" />

System mit einem Mikroprozessoren und weiteren Komponenten mit Master-Funktion (ohne Cache)

- ZusaÌˆtzlicher Master (z.B. DMA Controller) kann Kontrolle uÌˆber Bus uÌˆbernehmen
  - Kann damit **unabhaÌˆngig** vom Prozessor auf Hauptspeicher zugreifen 
  - Mikroprozessor und Master teilen sich **gemeinsamen** Datenbereich

Mikroprozessorsystem mit DMA-Controller: <span style="color:red">Zugriff auf **veraltete Daten (stale data)** </span>

- Problem beim Write-Through-Verfahren

  - Situation

    1. DMA-Controller beschreibt eine Speicherzelle, deren Inhalt im Cache als guÌˆltig eingetragen war
    2. Der Prozessor fuÌˆhrt danach einen Lesezugriff mit der Adresse dieser Speicherzelle durch

    $\to$  <span style="color:red">Prozessor liest veraltetes Datum</span>

  - ğŸ”§ LÃ¶sung: **Non-Cachable Data**
    - der vom Prozessor und dem zusaÌˆtzlichen Master gemeinsam benutzte Speicherbereich wird von der Speicherung im Cache **ausgeschlossen**
    - Aufgabe der Speicherverwaltung
      - Dieser Adressbereich als ***â€non-cacheableâ€œ*** gekennzeichnet
      - Die Cache-Steuerung wird bei Zugriffen auf den so gekennzeichneten Bereich NICHT aktiv.
      - Es werden auch die fuÌˆr Schnittstellen und Controller reservierten Adressbereiche als ***â€non-cacheableâ€œ*** gekennzeichnet, um den direkten Zugriff auf deren Daten-; Steuer- und Statusregister zu gewaÌˆhrleisten.

- Problem beim Copy-Back-Verfahren

  - Situation

    1. Der Prozessor fuÌˆhrt Schreibzugriff mit der Adresse aus dem gemeinsamen Bereich aus und aktualisiert nur Cache
    2. Der DMA-Controller liest anschlieÃŸend die Speicherzelle mit dieser Adresse

    $\to$  <span style="color:red">Der DMA-Controller liest veraltetes Datum (im Hauptspeicher)</span>

  - ğŸ”§ LÃ¶sung: **Cache-Clear, Cache-Flush**

    - Die Zugriffe von Prozessor und DMA-Controller auf den gemeinsamen Datenbereich werden von **zwei unterschiedlichen Tasks** ausgefuÌˆhrt;

    - In diesem Fall kann die Task, die den DMA-Vorgang ausloÌˆst, dafuÌˆr sorgen, dass der Cache geloÌˆscht wird (d.h nachfolgende Prozessorzugriffe fuÌˆhren zu einem Neuladen des Cache)

    - **Write-Through: Cache-Clear**

      Die Cache-EintraÌˆge werden auf *unguÌˆltig* gesetzt.

    - **Copy-Back: Cache-Flush**

      Alle mit â€dirtyâ€œ gekennzeichneten EintraÌˆge im Cache werden in den Hauptspeicher zuruÌˆckgeschrieben, danach werden Cache-EintraÌˆge auf unguÌˆltig gesetzt.

### 2. Fall: Speichergekoppeltes Multiprozessorsystem

<img src="https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/æˆªå±2020-07-29%2012.00.41.png" alt="æˆªå±2020-07-29 12.00.41" style="zoom:80%;" />

Mehrere Prozessoren mit **jeweils eigenen Cache-Speichern** sind uÌˆber einem Systembus an einen gemeinsamen Hauptspeicher angebunden.



## Cache-KohaÌˆrenz und Konsistenz

### Vereinfachte und intuitive Definition

- Ein Speichersystem ist **kohaÌˆrent**, wenn jeder Lesezugriff auf ein Datum den aktuell geschriebenen Wert dieses Datums liefert

- **KohaÌˆrenz**: definiert, *welcher* Wert bei einem Lesezugriff geliefert wird
- **Konsistenz**: bestimmt, *wann* ein geschriebener Wert bei einem Lesezugriff geliefert wird

### KohÃ¤renz

Ein Speichersystem ist **kohaÌˆrent**, wenn

- Einhaltung der Programmordnung

  <img src="https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/æˆªå±2020-07-29%2012.31.30.png" alt="æˆªå±2020-07-29 12.31.30" style="zoom:80%;" />

  Ein Lesezugriff eines Prozessors P auf eine Speicherstelle X, der einem Schreibzugriff von P auf die Stelle X folgt und KEINE Schreibzugriffe anderer Prozessoren zwischen dem Schreiben und dem Lesen von P stattfinden, liefert immer den Wert, den P geschrieben hat.

- KohaÌˆrente Sicht des Speichers

  <img src="https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/æˆªå±2020-07-29%2012.33.57.png" alt="æˆªå±2020-07-29 12.33.57" style="zoom:80%;" />

  Ein Lesezugriff eines Prozessors P auf eine Speicherstelle X, der auf einen Schreibzugriff eines anderen Prozessors auf die Stelle X folgt, liefert den geschriebenen Wert, falls der Lese- und Schreibzugriff **zeitlich ausreichend getrennt erfolgen und in der Zwischenzeit keine anderen Schreibzugriffe auf die Stelle X erfolgen**.

- Write Serialization

  Schreibzugriffe auf die eine Speicherzelle serialisiert werden; d.h. zwei Schreibzugriffe auf eine Speicherstelle durch zwei Prozessoren werden durch die anderen Prozessoren in der selben Reihenfolge gesehen.

### Konsistenz

Frage: Wann wird ein geschriebener Wert sichtbar?

- Man kann NICHT fordern, dass ein Lesezugriff auf eine Stelle X *sofort* den Wert liefert, der von einem Schreibzugriff auf X eines anderen Prozessors stammt
- **Konsistenzmodell**: Strategie, wann ein Prozessor die Schreiboperationen eines anderen Prozessors sieht



## KohaÌˆrenz-Protokolle

Ein paralleles Programm, das auf einem Multiprozessor laÌˆuft, kann mehrere Kopien eines Datums in mehreren Caches haben

- **Migration** bei kohaÌˆrenten Caches
  - Daten koÌˆnnen zu einem lokalen Cache migrieren und dort in einer transparenten Weise verwendet werden
  - Reduziert die Latenz fuÌˆr einen Zugriff auf ein gemeinsames Datum, das auf einem entfernten Speicher liegt :clap:
  - Reduziert auch die erforderliche Bandbreite auf den gemeinsamen Speicher :clap:
- **Replikation** bei kohaÌˆrenten Caches
  - Gemeinsame Daten koÌˆnnen in als Kopien in lokalen Caches vorliegen, wenn beispielsweise diese Daten gleichzeitig gelesen werden
  - Reduziert die Latenz der Zugriffe und die MoÌˆglichkeit einer Blockierung beim Zugriff auf das gemeinsame Datum :clap:

### Write-invalidate & Write-update

- **Write-invalidate-Protokoll**
  - Sicherstellen, dass ein Prozessor *exklusiven Zugriff* auf ein Datum hat, bevor er schreiben darf
  - Vor dem VeraÌˆndern einer Kopie in einem Cache-Speicher muÌˆssen alle Kopien in anderen Cache-Speichern fuÌˆr â€*unguÌˆltig*â€œ erklaÌˆrt werden ($\to$ "invalidate")

- **Write-update-Protokoll**
  - Beim VeraÌˆndern einer Kopie in einem Cache-Speicher muÌˆssen alle Kopien in anderen Cache-Speichern *ebenfalls* *veraÌˆndert* werden, wobei die Aktualisierung auch verzoÌˆgert (spaÌˆtestens beim Zugriff) erfolgen kann

- Vergleich: 

  - Mehrfaches Schreiben auf eine Stelle OHNE dazwischen auftauchende Lesezugriffe

    - Write-Update: erfordert mehrere Broadcast-Schreiboperationen
    - Write-Invalidate: Nur eine Invalidierung

  - Cache-Zeilen mit mehreren WoÌˆrtern

    - Write-Update

      - Arbeitet auf WoÌˆrtern

      - FuÌˆr jedes Wort in einem Block, das geschrieben wurde, ist ein Write- Broadcast notwendig

    - Write-Invalidate

      - Die erste Schreiboperation auf ein Wort eines Cache-Blocks erfordert eine Invalidierung

### Hardware-LoÌˆsung

- **Tabellen-basierte Protokolle (directory-based protocols)**

  Der Zustand eines Blocks im physikalischen Speicher wird in einer Tabelle (directory) festgehalten

- **Snooping-Protokolle (Bus-SchnuÌˆffeln)**
  - Jeder Cache, der eine Kopie der Daten eines Blocks des physikalischen Speichers enthaÌˆlt, hat ebenso eine Kopie des Zustands, in dem sich der Block befindet
  - KEIN zentraler Zustand wird festgehalten
  - Caches sind an einem gemeinsamen Bus und alle Cache-Controller beobachten (oder schnuÌˆffeln) am Bus, um bestimmen zu koÌˆnnen, ob sie eine Kopie eines Blocks enthalten, der benoÌˆtigt wird

### MESI-KohaÌˆrenzprotokoll

- Jeder Cache verfuÌˆgt uÌˆber **Snoop-Logik und Steuersignale**

  - **Invalidate-Signal**

    Invalidieren von EintraÌˆgen in den Caches anderer Prozessoren.

  - **Shared-Signal**

    Anzeige, ob ein zu ladender Block bereits als Kopie vorhanden ist.

  - **Retry-Signal**

    Aufforderung fuÌˆr einen Prozessor, das Laden eines Blockes abzubrechen. Das Laden wird dann wieder aufgenommen, wenn ein anderer Prozessor aus dem Cache in den Hauptspeicher zuruÌˆck geschrieben hat.

- Jede Cache-Zeile ist um zwei **Statusbits** erweitert,  um die ProtokollzustÃ¤nde anzuzeigen
  - **Invalid (I)**

    Die betrachtete Cache-Zeile ist *unguÌˆltig*

    - Lese- und Schreibzugriff auf diese Zeile veranlassen die Cache-Steuerung, den Speicherblock in die Cache-Zeile zu laden.
    - Die anderen Cache-Steuerungen, die den Bus beobachten, zeigen mit Hilfe des Shared-Signals an, ob dieser Block *gespeichert ist (Shared Read Miss)* oder *nicht (Exclusive Read Miss).*

  - **Shared (S)**

    Shared Unmodified: der Speicherblock existiert als Kopie in der Zeile des betrachteten Caches sowie gegebenenfalls in anderen Caches.

    - Lesezugriff auf die Cache-Zeile (Read-Hit): 
      - Der Zustand wird nicht veraÌˆndert.
    - Schreibzugriff auf die Cache-Zeile (Write-Hit): 
      - Die Cache-Zeile wird geaÌˆndert und geht in den Zustand M uÌˆber.
    - Ausgeben des Invalidate-Signals, woraufhin die Caches, bei denen diese Cache-Zeile ebenfalls im Zustand S ist, diese als unguÌˆltig kennzeichnen (Zustand **I**).

  - **Exclusive (E)** 

    Exclusive Unmodified: Der Speicherblock existiert als Kopie nur in der Zeile des betrachteten Caches.

    - Der Prozessor kann lesend und schreiben zugreifen, OHNE den Bus benuÌˆtzen zu muÌˆssen.
    - Schreibzugriff:
      - Wechseln in den Zustand M. 
      - Andere Caches sind nicht betroffen.

  - **Modified (M)**

    Exclusive Modified: Der Speicherblock existiert als Kopie NUR in der Zeile des betrachteten Caches. Er wurde nach dem Laden veraÌˆndert.

    - Der Prozessor kann lesend und schreibend zugreifen, OHNE den Bus benuÌˆtzen zu muÌˆssen.

    - Bei einem Lese- oder Schreibzugriff eines anderen Prozessors auf diesen Block (Snoop-Hit) muss dieser in den Hauptspeicher zuruÌˆckkopiert werden.

      - Snoop-Hit on a Read: M $\to$ S

      - Snoop-Hit on a Write or Read with Intend to Modify: M $\to$ I

    - Der Prozessor, der diesen Block aus dem Hauptspeicher holen will, wird mit Hilfe des Retry-Signals daruÌˆber informiert, dass zunaÌˆchst ein *ZuruÌˆckschreiben* erforderlich ist.

#### Zustandsgraph (lokale Lese- und Schreibzugriffe)

ZustandsuÌˆbergaÌˆnge durch lokale Lese- und Schreibzugriffe (d.h. Zugriffe des Prozessors)

<img src="https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/æˆªå±2020-07-29%2015.25.26.png" alt="æˆªå±2020-07-29 15.25.26" style="zoom:80%;" />

#### Zustandsgraph (auÃŸene Lese- und Schreibzugriffe)

ZustandsuÌˆbergaÌˆnge , die sich durch Beeinflussung von auÃŸen, von Seiten des Busses ergeben. Steuerung durch Snoop-Logik

<img src="https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/æˆªå±2020-07-29%2016.25.48.png" alt="æˆªå±2020-07-29 16.25.48" style="zoom:80%;" />

#### Wirkungsweise

Bsp: ein Mikroprozessorsystem mit 2 Prozessoren

- Vier aufeinander folgende Zugriffe auf ein und denselben Speicherblock

<img src="https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/æˆªå±2020-07-29%2016.30.23.png" alt="æˆªå±2020-07-29 16.30.23" style="zoom:80%;" />

<img src="https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/æˆªå±2020-07-29%2016.30.59.png" alt="æˆªå±2020-07-29 16.30.59" style="zoom:80%;" />

<img src="https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/æˆªå±2020-07-29%2016.31.06.png" alt="æˆªå±2020-07-29 16.31.06" style="zoom:80%;" />

<img src="https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/æˆªå±2020-07-29%2016.31.36.png" alt="æˆªå±2020-07-29 16.31.36" style="zoom:80%;" />

<img src="https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/æˆªå±2020-07-29%2016.31.55.png" alt="æˆªå±2020-07-29 16.31.55" style="zoom:80%;" />

### Multiprozessor mit verteiltem gemeinsamem Speicher, Distributed Shared Memory (DSM)

![æˆªå±2020-07-29 16.33.02](https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/æˆªå±2020-07-29%2016.33.02.png)

- KEINE MoÌˆglichkeit, die Broadcast-Eigenschaft des Busses zu nutzen ğŸ¤ª

- Verzeichnisbasierte (tabellenbasierte) Cache-KohaÌˆrenzprotokolle **(directory based)**



### Speicherkonsistenz

**Wichtige Fragen**:

- **Wann** muss ein Prozessor den Wert sehen, den ein anderer Prozessor aktualisiert hat?

- In **welcher Reihenfolge** muss ein Prozessor die Schreiboperationen eines anderen Prozessors beobachten?

- **Welche Bedingungen** zwischen Lese- und Schreiboperationen auf verschiedene Speicherstellen durch verschiedene Prozessoren muÌˆssen gelten?

### Speicherkonsistenzmodelle

Spezifizieren die Reihenfolge, in der Speicherzugriffe eines Prozesses von anderen Prozessen gesehen werden

#### Sequentielle Konsistenz

<img src="https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/æˆªå±2020-07-29%2016.41.44.png" alt="æˆªå±2020-07-29 16.41.44" style="zoom:80%;" />

- Ein Multiprozessorsystem heiÃŸt **sequentiell konsistent**, wenn das Ergebnis einer beliebigen Berechnung *dasselbe* ist, *als wenn die Operationen aller Prozessoren auf einem Einprozessorsystem in einer sequentiellen Ordnung ausgefuÌˆhrt wuÌˆrden.* Dabei ist die Ordnung der Operationen der Prozessoren die des jeweiligen Programms.
- Alle Lese- und Schreibzugriffe werden in einer beliebigen sequentiellen Reihenfolge, die jedoch mit den jeweiligen Programmordnungen konform ist, am Speicher wirksam.
- Entspricht einer uÌˆberlappenden sequentiellen AusfuÌˆhrung sequentieller Operationsfolgen anstelle einer parallelen AusfuÌˆhrung
- Schreibzugriffe muÌˆssen **atomisch** sein, d. h. der jeweilige Wert muss uÌˆberall gleichzeitig wirksam sein
- Nachteile
  - FuÌˆhrt zu <span style="color:red">sehr starken EinbuÃŸen bzgl. Implementierung und damit der Leistung</span>
  - Verbietet vorgezogene Ladeoperationen, nichtblockierende Caches

#### AbgeschwaÌˆchte Konsistenzmodelle

- Konsistenz NUR zum Zeitpunkt einer Synchronisationsoperation
- Lese- und Schreiboperationen der parallel arbeitenden Prozessoren auf den gemeinsamen Speicher zwischen den Synchronisationszeitpunkten koÌˆnnen in *beliebiger* geschehen.
- Konkurrierende Zugriffe auf gemeinsame Daten werden durch **geeignete Synchronisationen** geschuÌˆtzt
- ğŸ’¡Idee
  - Die Konsistenz des Speicherzugriffs wird nicht mehr zu allen Zeiten gewaÌˆhrleistet, sondern zu **bestimmten, vom Programmierer in das Programm eingesetzten Synchronisationspunkten**
  - Kritische Bereiche
    - Innerhalb dieser Bereiche: Inkonsistenz der gemeinsamen Daten zugelassen
    - Voraussetzung: konkurrierende Lese-/Schreibzugriffe sind durch den kritischen Bereiche unterbunden
    - Synchronisationspunkte: die Ein-/ und Austrittpunkte der kritischen Bereiche
- Bedingungen
  - Bevor ein Schreib- oder Lesezugriff bezuÌˆglich irgendeines anderen Prozessors ausgefuÌˆhrt werden darf, muÌˆssen ALLE vorhergehenden Synchronisationspunkte erreicht worden sein
  - Bevor eine Synchronisation bezuÌˆglich irgendeines anderen Prozessors ausgefuÌˆhrt werden darf, muÌˆssen ALLE vorhergehenden Schreib- oder Lesezugriffe ausgefuÌˆhrt worden sein.
  - Synchronisationspunkte muÌˆssen **sequentiell konsistent** sein

- Auswrikung

  Synchronisationsbefehle stellen HuÌˆrden dar, die von keinem Lese- oder Schreibzugriff uÌˆbersprungen werden

- Voraussetzung fuÌˆr die Implementierung der schwachen Konsistenz

  hardware- und softwaremaÌˆÃŸige Unterscheidung der Synchronisationsbefehle von den Lade- und Speicherbefehlen und eine sequentiell konsistente Implementierung der Synchronisationsbefehle